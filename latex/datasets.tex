\section{Datasets Description}
\subsection{DAIC-WOZ}
The DAIC-WOZ dataset is an essential resource in computational psychiatry, pivotal for developing algorithms to diagnose psychological distress conditions such as depression and anxiety. This publicly available English depression dataset features multimodal data including audio, video, and text transcripts of interviews conducted by an animated virtual agent named Ellie in a simulated clinical setting. The dataset includes 142 participants evaluated with the PHQ-8 score\cite{phq8}, a popular depression screening tool. A PHQ-8 score of 10 or higher is indicative of depression.

The dataset is divided into several subsets: the training set includes data from 30 depressed and 77 non-depressed participants, the development set consists of 12 depressed and 23 non-depressed participants, and the test set, which is not publicly available. This structure provides a rich, controlled environment for testing and comparing different diagnostic approaches, enhancing the reliability and accuracy of mental health diagnostics.

Interviews are designed to elicit emotional responses through predefined prompts, making the dataset highly suitable for studying vocal characteristics, speech patterns, non-verbal cues, and facial expressions associated with mental health states. The extensive annotations related to behavioral markers allow researchers to explore multimodal integration techniques, further supporting the development of sophisticated diagnostic models. This comprehensive data and detailed annotations are invaluable for advancing methodologies in mental health assessments within artificial intelligence frameworks.
\subsection{EATD-Corpus}
The Emotional Audio-Textual Depression (EATD) Corpus, created at Tongji University, is a unique dataset that caters to the need for multimodal data in depression research. This dataset includes audio recordings and their corresponding textual transcripts from interviews conducted with both depressed and non-depressed volunteers, making it a vital resource for the development of automated depression detection systems.

The EATD-Corpus is distinctive as it is the first publicly available Chinese dataset that integrates both audio and text modalities specifically for depression analysis. It comprises contributions from 162 student volunteers who provided informed consent, ensuring the data's authenticity and ethical integrity. Each session in the dataset is annotated according to the Self-Rating Depression Scale (SDS)\cite{SDS}, providing researchers with valuable clinical metrics to correlate with linguistic and acoustic features.

The comprehensive nature of this dataset allows for extensive research opportunities, including the enhancement of feature extraction methods for depression detection and the development of AI-driven models that utilize multimodal data to assess mental health states more accurately. Moreover, it supports the exploration of computational techniques in identifying depressive symptoms, thereby advancing the field of mental health technology.

This corpus not only enriches the tools available to researchers but also supports the development of sophisticated, accessible, and non-invasive diagnostic and treatment tools for mental health, aligning with the broader goals of improving mental health care through technology.