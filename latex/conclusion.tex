% \section{Conclusion}
% This study examined the effectiveness of using vocal biomarkers for depression detection through machine learning approaches, specifically comparing Decision Tree and TCC models across the DAIC-WOZ and EATD-Corpus datasets. While the Decision Tree model achieved the highest accuracy of 66\% on unseen data from the DAIC dataset, the results raise important questions about the practical utility of audio-based depression detection systems.
% A critical finding of this research is that traditional survey methods like PHQ-8 and PHQ-9 questionnaires remain more reliable and efficient tools for depression screening compared to complex machine learning models. These surveys provide immediate, validated results without the technical complexities and potential biases inherent in audio-based systems.
% The study revealed significant challenges in model generalization, particularly when dealing with completely unseen participants. Notably, many high-accuracy results reported in the literature (90-95\%) were achieved by mixing audio samples from the same participants in both training and test sets, which does not reflect real-world application scenarios. The substantial performance drop observed when testing on completely new participants highlights a critical limitation in current audio-based depression detection approaches.
% Furthermore, the varying performance of different feature extraction methods (MFCC vs. MCC) and model architectures demonstrates the inherent instability in audio-based detection systems. This variability, combined with the immediate availability and reliability of standardized questionnaires, suggests that the development of audio-based depression detection systems may be more academically interesting than practically necessary for current clinical applications.

\section{Conclusion}
This study examined the effectiveness of using vocal biomarkers for depression detection through machine learning approaches, specifically comparing Decision Tree and TCC models across the DAIC-WOZ and EATD-Corpus datasets. While the Decision Tree model achieved an accuracy of 66\% on unseen data from the DAIC dataset using a speaker-independent approach, the results raise important questions about the practical utility of audio-based depression detection systems.

A critical finding of my research is the significant disparity between speaker-dependent and speaker-independent approaches in depression detection. Many studies report impressive accuracies (90-95\%) using speaker-dependent setups, where audio segments from the same participants appear in both training and test sets. However, these results are misleading as they primarily demonstrate the model's ability to recognize individual speech patterns rather than depression indicators. In contrast, my speaker-independent evaluation, which better reflects real-world scenarios by testing on completely unseen participants, achieved more modest but realistic performance metrics.

The challenges extend beyond speaker dependency issues. Traditional survey methods like PHQ-8 and PHQ-9 questionnaires remain more reliable and efficient tools for depression screening compared to complex machine learning models. These surveys provide immediate, validated results without the technical complexities and potential biases inherent in audio-based systems. Additionally, the varying performance observed with different feature extraction methods (MFCC vs. MCC) and model architectures demonstrates the inherent instability in audio-based detection systems.

While this research contributes to my understanding of machine learning applications in mental health, it also highlights the importance of rigorous evaluation methodologies that prioritize real-world applicability. The substantial performance gap between speaker-dependent and speaker-independent approaches, combined with the immediate availability and reliability of standardized questionnaires, suggests that current audio-based depression detection systems may have more academic value than practical clinical utility. Future research in this field should focus on developing robust speaker-independent models and establishing clear evaluation protocols that better reflect deployment conditions.