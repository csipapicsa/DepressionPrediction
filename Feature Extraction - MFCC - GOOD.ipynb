{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract only MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dev\n",
    "import importlib as imp\n",
    "\n",
    "import functions\n",
    "imp.reload(functions)\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"datasets/DAIC-WOZ/\"\n",
    "files = os.listdir(BASE_PATH+\"/cuts\")\n",
    "df_train = pd.read_csv(BASE_PATH + \"train_split_Depression_AVEC2017.csv\")\n",
    "df_dev = pd.read_csv(BASE_PATH + \"dev_split_Depression_AVEC2017.csv\")\n",
    "df_dev = df_dev[['Participant_ID', 'PHQ8_Binary', 'PHQ8_Score']]\n",
    "df_train = df_train[['Participant_ID', 'PHQ8_Binary', 'PHQ8_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(file_path, sr=16000):\n",
    "    \"\"\"\n",
    "    Process each valid speech segment\n",
    "    \"\"\"\n",
    "\n",
    "    audio, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mfcc=40,  # 40 MFCC features\n",
    "        hop_length=int(sr * 0.010),  # 10ms stride\n",
    "        n_fft=int(sr * 0.025)  # 25ms window\n",
    "    )\n",
    "    \n",
    "    # Normalize each feature\n",
    "    mfcc = (mfcc - mfcc.mean(axis=1, keepdims=True)) / (mfcc.std(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def get_fixed_length_segments(mfcc, segment_length=200):\n",
    "    \"\"\"\n",
    "    Ensure each MFCC has fixed length by either padding or truncating\n",
    "    \"\"\"\n",
    "    current_length = mfcc.shape[1]\n",
    "    \n",
    "    if current_length > segment_length:\n",
    "        # Take center part if too long\n",
    "        start = (current_length - segment_length) // 2\n",
    "        return mfcc[:, start:start+segment_length]\n",
    "    elif current_length < segment_length:\n",
    "        # Pad with zeros if too short\n",
    "        padded = np.zeros((mfcc.shape[0], segment_length))\n",
    "        start = (segment_length - current_length) // 2\n",
    "        padded[:, start:start+current_length] = mfcc\n",
    "        return padded\n",
    "    else:\n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "307\n",
      "Processed 100 segments. Current MFCC shape: (40, 200)\n",
      "331\n",
      "335\n",
      "Processed 200 segments. Current MFCC shape: (40, 200)\n",
      "346\n",
      "Processed 300 segments. Current MFCC shape: (40, 200)\n",
      "367\n",
      "377\n",
      "Processed 400 segments. Current MFCC shape: (40, 200)\n",
      "381\n",
      "382\n",
      "Processed 500 segments. Current MFCC shape: (40, 200)\n",
      "388\n",
      "389\n",
      "Processed 600 segments. Current MFCC shape: (40, 200)\n",
      "390\n",
      "Processed 700 segments. Current MFCC shape: (40, 200)\n",
      "395\n",
      "403\n",
      "Processed 800 segments. Current MFCC shape: (40, 200)\n",
      "404\n",
      "406\n",
      "Processed 900 segments. Current MFCC shape: (40, 200)\n",
      "413\n",
      "417\n",
      "Processed 1000 segments. Current MFCC shape: (40, 200)\n",
      "418\n",
      "420\n",
      "Processed 1100 segments. Current MFCC shape: (40, 200)\n",
      "422\n",
      "436\n",
      "Processed 1200 segments. Current MFCC shape: (40, 200)\n",
      "439\n",
      "440\n",
      "Processed 1300 segments. Current MFCC shape: (40, 200)\n",
      "451\n",
      "458\n",
      "472\n",
      "Processed 1400 segments. Current MFCC shape: (40, 200)\n",
      "476\n",
      "477\n",
      "Processed 1500 segments. Current MFCC shape: (40, 200)\n",
      "482\n",
      "483\n",
      "Processed 1600 segments. Current MFCC shape: (40, 200)\n",
      "484\n",
      "489\n",
      "490\n",
      "492\n",
      "Final dataset shape: (1679, 40, 200)\n",
      "Labels shape: (1679,)\n"
     ]
    }
   ],
   "source": [
    "# Process all files\n",
    "base_path = BASE_PATH + \"cuts\"\n",
    "all_mfccs = []\n",
    "all_labels = []\n",
    "\n",
    "for _, row in df_dev.iterrows():\n",
    "    patient = row['Participant_ID']\n",
    "    print(patient)\n",
    "    label = row['PHQ8_Binary']  # Assuming this is your label\n",
    "    \n",
    "    patient_files = [f for f in os.listdir(base_path) \n",
    "                    if f.startswith(str(patient)) and f.endswith('.wav')]\n",
    "    \n",
    "    for f in patient_files:\n",
    "        file_path = f\"{base_path}/{f}\"\n",
    "        try:\n",
    "            # Extract MFCC\n",
    "            mfcc = process_segment(file_path)\n",
    "            \n",
    "            # Ensure fixed length\n",
    "            mfcc = get_fixed_length_segments(mfcc, segment_length=200)\n",
    "            \n",
    "            # Store MFCC and label\n",
    "            all_mfccs.append(mfcc)\n",
    "            all_labels.append(label)\n",
    "            \n",
    "            # Print shapes occasionally to verify\n",
    "            if len(all_mfccs) % 100 == 0:\n",
    "                print(f\"Processed {len(all_mfccs)} segments. Current MFCC shape: {mfcc.shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(all_mfccs)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# save X and y into a .npz file\n",
    "np.savez_compressed('DAIC_test.npz', X=X, y=y)\n",
    "\n",
    "print(f\"Final dataset shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('DAIC_train.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['303_segment_0.wav', '303_segment_1.wav', '303_segment_10.wav', '303_segment_11.wav', '303_segment_12.wav', '303_segment_13.wav', '303_segment_14.wav', '303_segment_15.wav', '303_segment_16.wav', '303_segment_17.wav', '303_segment_18.wav', '303_segment_19.wav', '303_segment_2.wav', '303_segment_20.wav', '303_segment_21.wav', '303_segment_22.wav', '303_segment_23.wav', '303_segment_24.wav', '303_segment_25.wav', '303_segment_26.wav', '303_segment_27.wav', '303_segment_28.wav', '303_segment_29.wav', '303_segment_3.wav', '303_segment_30.wav', '303_segment_31.wav', '303_segment_32.wav', '303_segment_33.wav', '303_segment_34.wav', '303_segment_35.wav', '303_segment_36.wav', '303_segment_37.wav', '303_segment_38.wav', '303_segment_39.wav', '303_segment_4.wav', '303_segment_40.wav', '303_segment_41.wav', '303_segment_42.wav', '303_segment_43.wav', '303_segment_44.wav', '303_segment_45.wav', '303_segment_46.wav', '303_segment_47.wav', '303_segment_48.wav', '303_segment_49.wav', '303_segment_5.wav', '303_segment_50.wav', '303_segment_51.wav', '303_segment_52.wav', '303_segment_53.wav', '303_segment_54.wav', '303_segment_55.wav', '303_segment_56.wav', '303_segment_6.wav', '303_segment_7.wav', '303_segment_8.wav', '303_segment_9.wav']\n",
      "datasets/DAIC-WOZ/cuts/303_segment_0.wav\n"
     ]
    },
    {
     "ename": "ParameterError",
     "evalue": "Audio data must be of type numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_path)\n\u001b[1;32m---> 10\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(mfcc)\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mprocess_segment\u001b[1;34m(audio_segment, sr)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mProcess each valid speech segment\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract MFCC features\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_segment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 40 MFCC features\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.010\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 10ms stride\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.025\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 25ms window\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Normalize each feature\u001b[39;00m\n\u001b[0;32m     15\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m (mfcc \u001b[38;5;241m-\u001b[39m mfcc\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m/\u001b[39m (mfcc\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\feature\\spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \n\u001b[0;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1993\u001b[0m ]\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\feature\\spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \n\u001b[0;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:2945\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m   2941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2942\u001b[0m         )\n\u001b[0;32m   2943\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2944\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m-> 2945\u001b[0m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2946\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2947\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2948\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2949\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2950\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2951\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2952\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2953\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2954\u001b[0m         )\n\u001b[0;32m   2955\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m   2956\u001b[0m     )\n\u001b[0;32m   2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\spectrum.py:239\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhop_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhop_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Check audio is valid\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m fft_window \u001b[38;5;241m=\u001b[39m get_window(window, win_length, fftbins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Pad the window out to n_fft size\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\util\\utils.py:295\u001b[0m, in \u001b[0;36mvalid_audio\u001b[1;34m(y, mono)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine whether a variable contains valid audio data.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mThe following conditions must be satisfied:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03mnumpy.float32\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be of type numpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(y\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudio data must be floating-point\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mParameterError\u001b[0m: Audio data must be of type numpy.ndarray"
     ]
    }
   ],
   "source": [
    "base_path = BASE_PATH+\"cuts\"\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    patient = row['Participant_ID']\n",
    "    patient_files = [f for f in os.listdir(base_path) if f.startswith(str(patient)) and f.endswith('.wav')]\n",
    "    print(patient_files)s\n",
    "    for f in patient_files:\n",
    "        file_path = f\"{base_path}/{f}\"\n",
    "        print(file_path)\n",
    "        mfcc = process_segment(file_path)\n",
    "        print(mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
