{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "### load data and labels\n",
    "### mfcc has various lengths \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data and labels\n",
    "### mfcc has various lengths \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def segment_mfcc(mfcc, max_segment_length=200):\n",
    "    # Segment the MFCC array into fixed lengths with possible overlap (if desired)\n",
    "    # segment_length is the fixed length of each segment\n",
    "    segments = []\n",
    "    for start in range(0, mfcc.shape[1], max_segment_length):\n",
    "        end = start + max_segment_length\n",
    "        if end < mfcc.shape[1]:\n",
    "            segments.append(mfcc[:, start:end])\n",
    "        else:\n",
    "            # Padding the last segment if it's shorter than the required segment length\n",
    "            segments.append(np.pad(mfcc[:, start:], ((0,0), (0, max_segment_length - (mfcc.shape[1] - start))), 'constant'))\n",
    "    return segments\n",
    "\n",
    "def load_concatenated_mfcc(path):\n",
    "    \n",
    "    # Load the concatenated MFCC data\n",
    "    data = np.load(path)\n",
    "    return data['mfcc']\n",
    "\n",
    "df = pd.read_csv('datasets/DAIC-WOZ/Patient_Classes.csv')\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     patient_id = row['Participant_ID']\n",
    "#     label = row['PHQ8_Binary']\n",
    "#     train_or_test = row['dataset'] # test or dev\n",
    "#     mfcc_path = 'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_'+str(patient_id)+'.npz'\n",
    "#     try:\n",
    "#         mfcc = load_concatenated_mfcc(mfcc_path) # the raw mfcc data\n",
    "#         # make a dataset to be able to train the CNN\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         continue\n",
    "\n",
    "def create_datasets(df, max_segment_length=500):\n",
    "    dataset = {'train': [], 'test': []}\n",
    "    labels = {'train': [], 'test': []}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        patient_id = row['Participant_ID']\n",
    "        label = row['PHQ8_Binary']\n",
    "        print(patient_id, label)\n",
    "        train_or_test = row['dataset']  # Could be 'train' or 'test'\n",
    "        # if train_or_test is 'dev' change it to 'test'\n",
    "        if train_or_test == 'dev':\n",
    "            train_or_test = 'test'\n",
    "\n",
    "        mfcc_path = f'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_{patient_id}.npz'\n",
    "\n",
    "        try:\n",
    "            mfcc = load_concatenated_mfcc(mfcc_path)  # Load the raw MFCC data\n",
    "            segments = segment_mfcc(mfcc, max_segment_length=max_segment_length)\n",
    "            \n",
    "            # Append each segment to the corresponding dataset\n",
    "            for segment in segments:\n",
    "                dataset[train_or_test].append(segment)\n",
    "                labels[train_or_test].append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process patient {patient_id}: {e}\")\n",
    "\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 0\n",
      "304 0\n",
      "305 0\n",
      "310 0\n",
      "312 0\n",
      "313 0\n",
      "315 0\n",
      "316 0\n",
      "317 0\n",
      "318 0\n",
      "319 1\n",
      "320 1\n",
      "321 1\n",
      "322 0\n",
      "324 0\n",
      "325 1\n",
      "326 0\n",
      "327 0\n",
      "328 0\n",
      "330 1\n",
      "333 0\n",
      "336 0\n",
      "338 1\n",
      "339 1\n",
      "340 0\n",
      "341 0\n",
      "343 0\n",
      "344 1\n",
      "345 1\n",
      "347 1\n",
      "348 1\n",
      "350 1\n",
      "351 1\n",
      "352 1\n",
      "353 1\n",
      "355 1\n",
      "356 1\n",
      "357 0\n",
      "358 0\n",
      "360 0\n",
      "362 1\n",
      "363 0\n",
      "364 0\n",
      "366 0\n",
      "368 0\n",
      "369 0\n",
      "370 0\n",
      "371 0\n",
      "372 1\n",
      "374 0\n",
      "375 0\n",
      "376 1\n",
      "379 0\n",
      "380 1\n",
      "383 0\n",
      "385 0\n",
      "386 1\n",
      "391 0\n",
      "392 0\n",
      "393 0\n",
      "397 0\n",
      "400 0\n",
      "401 0\n",
      "402 1\n",
      "409 0\n",
      "412 1\n",
      "414 1\n",
      "415 0\n",
      "416 0\n",
      "419 0\n",
      "423 0\n",
      "425 0\n",
      "426 1\n",
      "427 0\n",
      "428 0\n",
      "429 0\n",
      "430 0\n",
      "433 1\n",
      "434 0\n",
      "437 0\n",
      "441 1\n",
      "443 0\n",
      "444 0\n",
      "445 0\n",
      "446 0\n",
      "447 0\n",
      "448 1\n",
      "449 0\n",
      "454 0\n",
      "455 0\n",
      "456 0\n",
      "457 0\n",
      "459 1\n",
      "463 0\n",
      "464 0\n",
      "468 0\n",
      "471 0\n",
      "473 0\n",
      "474 0\n",
      "475 0\n",
      "478 0\n",
      "479 0\n",
      "485 0\n",
      "486 0\n",
      "487 0\n",
      "488 0\n",
      "491 0\n",
      "Failed to process patient 491: [Errno 2] No such file or directory: 'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_491.npz'\n",
      "302 0\n",
      "307 0\n",
      "331 0\n",
      "335 1\n",
      "346 1\n",
      "367 1\n",
      "377 1\n",
      "381 1\n",
      "382 0\n",
      "388 1\n",
      "389 1\n",
      "390 0\n",
      "395 0\n",
      "403 0\n",
      "404 0\n",
      "406 0\n",
      "413 1\n",
      "417 0\n",
      "418 1\n",
      "420 0\n",
      "422 1\n",
      "436 0\n",
      "439 0\n",
      "440 1\n",
      "451 0\n",
      "458 0\n",
      "472 0\n",
      "476 0\n",
      "477 0\n",
      "482 0\n",
      "483 1\n",
      "484 0\n",
      "489 0\n",
      "Failed to process patient 489: [Errno 2] No such file or directory: 'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_489.npz'\n",
      "490 0\n",
      "Failed to process patient 490: [Errno 2] No such file or directory: 'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_490.npz'\n",
      "492 0\n",
      "Failed to process patient 492: [Errno 2] No such file or directory: 'datasets/DAIC-WOZ/ConcatenatedMFCC/concatenated_mfcc_492.npz'\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataloaders(dataset, labels, batch_size=32):\n",
    "    dataloaders = {}\n",
    "    for phase in ['train', 'test']:\n",
    "        features = torch.tensor(dataset[phase]).float()  # Convert features to float tensors\n",
    "        targets = torch.tensor(labels[phase]).long()  # Convert labels to long tensors\n",
    "\n",
    "        # Reshape for Conv1D: [batch, channels, length]\n",
    "        features = features.permute(0, 1, 2)\n",
    "\n",
    "        data_set = TensorDataset(features, targets)\n",
    "        dataloaders[phase] = DataLoader(data_set, batch_size=batch_size, shuffle=(phase == 'train'))\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "SEQMENT_LENGTH = 100\n",
    "# Assuming you have already loaded and segmented the data\n",
    "dataset, labels = create_datasets(df, max_segment_length=SEQMENT_LENGTH) \n",
    "# dataloaders = prepare_dataloaders(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, mfcc_features, labels):\n",
    "        self.features = torch.FloatTensor(mfcc_features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gergo Gyori\\AppData\\Local\\Temp\\ipykernel_8100\\587900977.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  self.features = torch.FloatTensor(mfcc_features)\n"
     ]
    }
   ],
   "source": [
    "dataset_train = AudioDataset(dataset[\"train\"], labels[\"test\"])\n",
    "dataset_val = AudioDataset(dataset[\"test\"], labels[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCC(nn.Module):\n",
    "    def __init__(self, input_features=40, sequence_length=200):\n",
    "        super(TCC, self).__init__()\n",
    "        \n",
    "        # Parallel CNN streams (as per paper Section 3.1)\n",
    "        self.cnn_stream1 = CNNStream()\n",
    "        self.cnn_stream2 = CNNStream()\n",
    "        \n",
    "        # Transformer stream with linear attention\n",
    "        self.transformer_stream = TransformerStream(input_features, sequence_length)\n",
    "        \n",
    "        # Fusion layer\n",
    "        cnn_out_size = 64 * (sequence_length // 8)  # After 3 max pooling layers\n",
    "        transformer_out_size = 512\n",
    "\n",
    "\n",
    "        # total_features = (cnn_out_size * 2) + transformer_out_size\n",
    "        total_features = (cnn_out_size * 2) + 128  # reduced from 512\n",
    "\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(total_features, 128), #reduce the number of features 512 was\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2)  # Binary classification # reduced from 512, 256, 128\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Parallel processing through streams\n",
    "        cnn1_out = self.cnn_stream1(x)\n",
    "        cnn2_out = self.cnn_stream2(x)\n",
    "        transformer_out = self.transformer_stream(x)\n",
    "        \n",
    "        # Flatten and concatenate\n",
    "        cnn1_out = cnn1_out.flatten(1)\n",
    "        cnn2_out = cnn2_out.flatten(1)\n",
    "        \n",
    "        # Fusion\n",
    "        combined = torch.cat([cnn1_out, cnn2_out, transformer_out], dim=1)\n",
    "        output = self.fusion(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class CNNStream(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNStream, self).__init__()\n",
    "        \n",
    "        # Three conv layers as specified in paper\n",
    "        self.layers = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv1d(40, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerStream(nn.Module):\n",
    "    def __init__(self, input_features, sequence_length):\n",
    "        super(TransformerStream, self).__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_features, 128) # 265 instead of 512\n",
    "        \n",
    "        # Four transformer layers with linear attention\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerLayer(d_model=128) for _ in range(2) # reduced to 256 from 512 range 4-> 2\n",
    "        ])\n",
    "        \n",
    "        # Output pooling\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transform input: [batch, features, seq] -> [batch, seq, features]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Project to transformer dimension\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Apply transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Global pooling over sequence dimension\n",
    "        x = x.transpose(1, 2)  # [batch, features, seq]\n",
    "        x = self.pool(x).squeeze(-1)  # [batch, features]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d_model=512):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        \n",
    "        # Linear attention with 4 heads\n",
    "        self.attention = LinearAttention(d_model, n_heads=4)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(2048, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer norms\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Multi-head attention with residual\n",
    "        attended = self.attention(x)\n",
    "        x = self.norm1(x + attended)\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        \n",
    "        # Linear projections\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.o_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Linear projections and reshape to heads\n",
    "        q = self.q_proj(x).view(batch_size, seq_len, self.n_heads, self.d_head)\n",
    "        k = self.k_proj(x).view(batch_size, seq_len, self.n_heads, self.d_head)\n",
    "        v = self.v_proj(x).view(batch_size, seq_len, self.n_heads, self.d_head)\n",
    "        \n",
    "        # Apply ELU + 1 for positive values (as per paper)\n",
    "        q = self.elu(q) + 1\n",
    "        k = self.elu(k) + 1\n",
    "        \n",
    "        # Linear attention computation\n",
    "        k_cumsum = k.sum(dim=1, keepdim=True)\n",
    "        D_inv = 1.0 / torch.einsum('bhnd,bhnd->bhn', q, k_cumsum)\n",
    "        context = torch.einsum('bhnd,bhne->bhde', k, v)\n",
    "        out = torch.einsum('bhnd,bhde,bhn->bhne', q, context, D_inv)\n",
    "        \n",
    "        # Reshape and project output\n",
    "        out = out.contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        out = self.o_proj(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=200, learning_rate=0.001, global_history=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "\n",
    "        # Initialize metric collectors\n",
    "    global_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        global_history['train_loss'].append(avg_train_loss*100)\n",
    "        global_history['val_loss'].append(avg_val_loss*100)\n",
    "        global_history['train_acc'].append(train_acc)\n",
    "        global_history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        # validation loss aand accuracy print\n",
    "        print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n')\n",
    "        print(40 * '-')\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                # break\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n')\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/10\n",
      "Train Loss: 0.5612, Train Acc: 70.62%\n",
      "Val Loss: 0.8520, Val Acc: 55.66%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 2/10\n",
      "Train Loss: 0.4639, Train Acc: 76.17%\n",
      "Val Loss: 0.9498, Val Acc: 53.56%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 3/10\n",
      "Train Loss: 0.4405, Train Acc: 77.70%\n",
      "Val Loss: 1.4964, Val Acc: 51.58%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 4/10\n",
      "Train Loss: 0.4245, Train Acc: 79.21%\n",
      "Val Loss: 1.0401, Val Acc: 54.17%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 5/10\n",
      "Train Loss: 0.4234, Train Acc: 78.97%\n",
      "Val Loss: 1.2335, Val Acc: 51.77%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 6/10\n",
      "Train Loss: 0.4166, Train Acc: 79.22%\n",
      "Val Loss: 1.4132, Val Acc: 54.42%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 7/10\n",
      "Train Loss: 0.4140, Train Acc: 79.51%\n",
      "Val Loss: 1.1106, Val Acc: 50.25%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 8/10\n",
      "Train Loss: 0.4081, Train Acc: 80.20%\n",
      "Val Loss: 1.3318, Val Acc: 51.99%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 9/10\n",
      "Train Loss: 0.3991, Train Acc: 81.21%\n",
      "Val Loss: 0.8666, Val Acc: 54.13%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch 10/10\n",
      "Train Loss: 0.4077, Train Acc: 80.94%\n",
      "Val Loss: 1.0620, Val Acc: 52.47%\n",
      "\n",
      "----------------------------------------\n",
      "Epoch [10/10]\n",
      "Train Loss: 0.4077, Train Acc: 80.94%\n",
      "Val Loss: 1.0620, Val Acc: 52.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "# set for reduced memory usage\n",
    "\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "global_history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "\n",
    "model = TCC(input_features=40, sequence_length=SEQMENT_LENGTH) \n",
    "model, history = train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001, global_history=global_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(global_history['train_loss'], label='Training Loss')\n",
    "# train loss each value is duplicated by 100\n",
    "\n",
    "plt.plot(global_history['val_loss'], label='Validation Loss')\n",
    "plt.plot(global_history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(global_history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
